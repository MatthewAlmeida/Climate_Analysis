{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7\n",
    "no_gpu = 8\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import cPickle as pickle\n",
    "import math\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import deepst.metrics as metrics\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "nb_epoch = 500  # number of epoch at training stage\n",
    "nb_epoch_cont = 100  # number of epoch at training (cont) stage\n",
    "batch_size = 32  # batch size\n",
    "\n",
    "lr = 0.0002  # learning rate\n",
    "len_closeness = 5  # length of closeness dependent sequence\n",
    "nb_residual_unit = 4   # number of residual units\n",
    "len_test = 784\n",
    "nb_flow = 1  # there are two types of flows: new-flow and end-flow\n",
    "# divide data into two subsets: Train & Test, of which the test set is the\n",
    "# last 10 days\n",
    "map_height, map_width = 480, 1440  # grid size\n",
    "# For NYC Bike data, there are 81 available grid-based areas, each of\n",
    "# which includes at least ONE bike station. Therefore, we modify the final\n",
    "# RMSE by multiplying the following factor (i.e., factor).\n",
    "\n",
    "path_result = 'RET'\n",
    "path_model = 'MODEL'\n",
    "\n",
    "if os.path.isdir(path_result) is False:\n",
    "    os.mkdir(path_result)\n",
    "if os.path.isdir(path_model) is False:\n",
    "    os.mkdir(path_model)\n",
    "data_path = '/notebooks/workspace/flood/www.ncei.noaa.gov/data/precipitation-persiann/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PERSIANN\n",
    "if os.path.isfile('X.npy') is False: \n",
    "    print ('create samples.')\n",
    "    path_data = '/notebooks/workspace/flood/www.ncei.noaa.gov/data/precipitation-persiann/'\n",
    "    path_Ganges = '/notebooks/workspace/Climate_Analysis/Data/GBM_Ganges.csv'\n",
    "    path_Brahmaputra = '/notebooks/workspace/Climate_Analysis/Data/GBM_Brahmaputra.csv'\n",
    "    path_Meghna = '/notebooks/workspace/Climate_Analysis/Data/GBM_Meghna.csv'\n",
    "    PERSIANN.create_samples(path_data,path_Ganges,path_Brahmaputra,path_Meghna)\n",
    "X = np.load('X.npy')\n",
    "Y_G = np.load('Y_G.npy')\n",
    "Y_B = np.load('Y_B.npy')\n",
    "Y_M = np.load('Y_M.npy')\n",
    "Y_ts = np.load('Y_ts.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (3486, 5, 480, 1440) Y_train shape (3486, 1) X_test shape (784, 5, 480, 1440) Y_test shape (784, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X_train, Y_train, X_test, Y_test = X[:-len_test],Y_G[:-len_test],X[-len_test:],Y_G[-len_test:]\n",
    "print ('X_train shape', X_train.shape, 'Y_train shape', Y_train.shape,'X_test shape', X_test.shape, 'Y_test shape', Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ResidualNet as RN\n",
    "from keras.utils import multi_gpu_model\n",
    "def build_model():\n",
    "    c_conf = (len_closeness, nb_flow, map_height,\n",
    "              map_width) if len_closeness > 0 else None\n",
    "\n",
    "    model = RN.stresnet(c_conf=c_conf, p_conf=None, t_conf=None,\n",
    "                     external_dim=None, nb_residual_unit=nb_residual_unit)\n",
    "    parallel_model = multi_gpu_model(model, gpus=no_gpu)\n",
    "    \n",
    "    adam = Adam(lr=lr)\n",
    "    parallel_model.compile(loss='mse', optimizer=adam, metrics=[metrics.rmse])\n",
    "    parallel_model.summary()\n",
    "    # from keras.utils.visualize_util import plot\n",
    "    # plot(model, to_file='model.png', show_shapes=True)\n",
    "    return parallel_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 64, 480, 1440)\n",
      "(?, 64, 480, 1440)\n",
      "(?, 64, 480, 1440)\n",
      "(?, 64, 480, 1440)\n",
      "(?, 64, 480, 1440)\n",
      "(?, 64, 480, 1440)\n",
      "(?, 64, 480, 1440)\n",
      "(?, 64, 480, 1440)\n",
      "here+++++++++++++++++++++++++++\n",
      "main_shape:  (?, 1, 480, 1440)\n",
      "external_dim: None\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 5, 480, 1440) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 5, 480, 1440) 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 5, 480, 1440) 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 5, 480, 1440) 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 5, 480, 1440) 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 5, 480, 1440) 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 5, 480, 1440) 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 5, 480, 1440) 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 5, 480, 1440) 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 1)            990146      lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Concatenate)     (None, 1)            0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "                                                                 model_1[3][0]                    \n",
      "                                                                 model_1[4][0]                    \n",
      "                                                                 model_1[5][0]                    \n",
      "                                                                 model_1[6][0]                    \n",
      "                                                                 model_1[7][0]                    \n",
      "                                                                 model_1[8][0]                    \n",
      "==================================================================================================\n",
      "Total params: 990,146\n",
      "Trainable params: 990,146\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "==========\n",
      "training model...\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "hyperparams_name = 'c{}.resunit{}.lr{}'.format(\n",
    "    len_closeness, nb_residual_unit, lr)\n",
    "fname_param = os.path.join('MODEL', '{}.best.h5'.format(hyperparams_name))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_rmse', patience=5, mode='min')\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    fname_param, monitor='val_rmse', verbose=0, save_best_only=True, mode='min')\n",
    "\n",
    "print('=' * 10)\n",
    "print(\"training model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3137 samples, validate on 349 samples\n",
      "Epoch 1/500\n",
      "3137/3137 [==============================] - 219s 70ms/step - loss: 193961165.8852 - rmse: 12827.0514 - val_loss: 75584808.7335 - val_rmse: 7807.6305\n",
      "Epoch 2/500\n",
      "3137/3137 [==============================] - 204s 65ms/step - loss: 53081813.3022 - rmse: 7174.9092 - val_loss: 150776232.9054 - val_rmse: 10933.0493\n",
      "Epoch 3/500\n",
      "3137/3137 [==============================] - 204s 65ms/step - loss: 28191899.9127 - rmse: 5239.8247 - val_loss: 97494143.1748 - val_rmse: 8847.9618\n",
      "Epoch 4/500\n",
      "3137/3137 [==============================] - 201s 64ms/step - loss: 17996338.0449 - rmse: 4168.9307 - val_loss: 215834042.4756 - val_rmse: 13478.6018\n",
      "Epoch 5/500\n",
      "3137/3137 [==============================] - 203s 65ms/step - loss: 11902514.5881 - rmse: 3387.0581 - val_loss: 57461386.0630 - val_rmse: 7014.4791\n",
      "Epoch 6/500\n",
      "3137/3137 [==============================] - 201s 64ms/step - loss: 9758708.6378 - rmse: 3023.1723 - val_loss: 153910935.5301 - val_rmse: 11292.9284\n",
      "Epoch 7/500\n",
      "3137/3137 [==============================] - 203s 65ms/step - loss: 4988705.3679 - rmse: 2198.1686 - val_loss: 88121273.9943 - val_rmse: 8511.9802\n",
      "Epoch 8/500\n",
      "3137/3137 [==============================] - 202s 65ms/step - loss: 3372279.5887 - rmse: 1813.6107 - val_loss: 106583000.5731 - val_rmse: 9422.7931\n",
      "Epoch 9/500\n",
      "3137/3137 [==============================] - 203s 65ms/step - loss: 2405006.7846 - rmse: 1532.8315 - val_loss: 122965605.3524 - val_rmse: 10147.2811\n",
      "Epoch 10/500\n",
      "3137/3137 [==============================] - 202s 64ms/step - loss: 2339356.7994 - rmse: 1501.0945 - val_loss: 141312882.2350 - val_rmse: 10934.7325\n",
      "==========\n",
      "evaluating using the model that has the best loss on the valid set\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping, model_checkpoint],\n",
    "                    verbose=1)\n",
    "model.save_weights(os.path.join(\n",
    "    'MODEL', '{}.h5'.format(hyperparams_name)), overwrite=True)\n",
    "pickle.dump((history.history), open(os.path.join(\n",
    "    path_result, '{}.history.pkl'.format(hyperparams_name)), 'wb'))\n",
    "\n",
    "print('=' * 10)\n",
    "print('evaluating using the model that has the best loss on the valid set')\n",
    "\n",
    "model.load_weights(fname_param)\n",
    "score = model.evaluate(X_train, Y_train, batch_size=Y_train.shape[\n",
    "                       0] // 48, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 29599410.065404 rmse (norm): 5342.950804\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Dst tensor is not initialized.\n\t [[Node: conv2d_1/kernel/read/_969 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:2\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_211_conv2d_1/kernel/read\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:2\"]()]]\n\t [[Node: replica_2/model_1/activation_10/Relu/_1309 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:2\", send_device_incarnation=1, tensor_name=\"edge_808_replica_2/model_1/activation_10/Relu\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7e1efd4d79ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m score = model.evaluate(\n\u001b[0;32m----> 5\u001b[0;31m     X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n\u001b[0m\u001b[1;32m      6\u001b[0m print('Test score: %.6f rmse (norm): %.6f' %\n\u001b[1;32m      7\u001b[0m       (score[0], score[1]))\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1109\u001b[0m                                          \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m                                          \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m                                          steps=steps)\n\u001b[0m\u001b[1;32m   1112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m     def predict(self, x,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training_arrays.pyc\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.pyc\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    520\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Dst tensor is not initialized.\n\t [[Node: conv2d_1/kernel/read/_969 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:2\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_211_conv2d_1/kernel/read\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:2\"]()]]\n\t [[Node: replica_2/model_1/activation_10/Relu/_1309 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:2\", send_device_incarnation=1, tensor_name=\"edge_808_replica_2/model_1/activation_10/Relu\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]"
     ]
    }
   ],
   "source": [
    "print('Train score: %.6f rmse (norm): %.6f' %\n",
    "      (score[0], score[1]))\n",
    "\n",
    "score = model.evaluate(\n",
    "    X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n",
    "print('Test score: %.6f rmse (norm): %.6f' %\n",
    "      (score[0], score[1]))\n",
    "\n",
    "print('=' * 10)\n",
    "print(\"training model (cont)...\")\n",
    "fname_param = os.path.join(\n",
    "    'MODEL', '{}.cont.best.h5'.format(hyperparams_name))\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    fname_param, monitor='rmse', verbose=0, save_best_only=True, mode='min')\n",
    "history = model.fit(X_train, Y_train, nb_epoch=nb_epoch_cont, verbose=1, batch_size=batch_size, callbacks=[\n",
    "                    model_checkpoint], validation_data=(X_test, Y_test))\n",
    "pickle.dump((history.history), open(os.path.join(\n",
    "    path_result, '{}.cont.history.pkl'.format(hyperparams_name)), 'wb'))\n",
    "model.save_weights(os.path.join(\n",
    "    'MODEL', '{}_cont.h5'.format(hyperparams_name)), overwrite=True)\n",
    "\n",
    "print('=' * 10)\n",
    "print('evaluating using the final model')\n",
    "score = model.evaluate(X_train, Y_train, batch_size=Y_train.shape[\n",
    "                       0] // 48, verbose=0)\n",
    "print('Train score: %.6f rmse (norm): %.6f' %\n",
    "      (score[0], score[1]))\n",
    "\n",
    "score = model.evaluate(\n",
    "    X_test, Y_test, batch_size=Y_test.shape[0], verbose=0)\n",
    "print('Test score: %.6f rmse (norm): %.6f' %\n",
    "      (score[0], score[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
